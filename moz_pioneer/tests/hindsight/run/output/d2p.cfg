filename        = "s3_parquet.lua"
message_matcher = "Type == 'pioneer'"
ticker_interval = 60
preserve_data   = false

parquet_schema = [=[
message pioneer_heatmap {
  required binary user (UTF8);
  required group sessions (LIST) {
    repeated group list {
      required group element {
        optional int64 duration;
        required int64 start_time;
        optional binary tab_id (UTF8);
        required binary url (UTF8);
      }
    }
  }
  required group metadata {
      required int64  Timestamp;
      required binary documentId (UTF8);
      optional binary geoCountry (UTF8);
      optional binary geoCity (UTF8);
  }
}]=]

metadata_group = "metadata"
json_objects = {"Fields[submission]"}
s3_path_dimensions  = {
    {name = "_submission_date", source = "Timestamp", dateformat = "%Y%m%d", scaling_factor = 1e-9}
}

-- directory location to store the intermediate output files
batch_dir           = "output/parquet"
max_writers         = 5
max_rowgroup_size   = 10000.
max_file_size       = 1024 * 1024 * 300
max_file_age        = 60 * 60
hive_compatible     = true -- default false
